{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters-21578 Text Categorization\n",
    "The goal of this section is to implement a machine learning model that correctly classifies a series of documents in the Reuters-21578 corpus. Each document's \"BODY\" and \"TITLE\" is used to predict the overall category, or \"TOPIC\", of the document.\n",
    "\n",
    "First, the frequency of top words in each document's \"BODY\" and \"TITLE\" is calculated and used to create a sparse matrix of features. The most popular \"TOPIC\" for each document comprises the list of labels\n",
    "\n",
    "The K-Means Clustering adds more value to analyzing the top words and groups them into 135 clusters, reflecting the 135 potential \"TOPICS\".\n",
    "\n",
    "The Naive Bayes algorithm uses two approaches to classify: SkLearn randomized the test_train_split and \"LEWISSPLIT\" predetermined split, which was used in the TOIS located in the Resources directory.\n",
    " - Using the SkLearn split, \"BODY\" accurately classfies \n",
    " - Using the \"LEWISSPLIT\", \"BODY\" classifies about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Top Words\n",
    "This section determines the frequencies of top words in the entire corpus. The words are taken from either the text \"BODY\" or \"TITLE\".\n",
    "\n",
    "Words that do not have an impact on the overall categorization of the article, or stopwords, such as \"and\" and \"the\" are removed from the list of words. A sparse matrix is created for the features and a separate list is created with a single topic for each document ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from yellowbrick.text.freqdist import FreqDistVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = frozenset({'reuter', 'said'})\n",
    "english_stopwords = stop_words.ENGLISH_STOP_WORDS\n",
    "stopwords = stopwords.union(english_stopwords)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = stopwords)\n",
    "\n",
    "def graph_frequencies(matrix, features):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    visualizer = FreqDistVisualizer(features=features, ax=ax)\n",
    "    visualizer.fit(matrix)\n",
    "    visualizer.poof()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a sparse matrix and populates features for BODY and TITLE\n",
    "with open('body_no_null.csv') as f:\n",
    "    bodyContent = f.readlines()\n",
    "bodyData = [x.split(',')[2] for x in bodyContent]\n",
    "bodyMatrix = vectorizer.fit_transform(bodyData)\n",
    "bodyFeatures = vectorizer.get_feature_names()\n",
    "graph_frequencies(bodyMatrix, bodyFeatures)\n",
    "\n",
    "with open('title_no_null.csv') as f:\n",
    "    titleContent = f.readlines()\n",
    "titleData = [x.split(',')[2] for x in titleContent]\n",
    "titleMatrix = vectorizer.fit_transform(titleData)\n",
    "titleFeatures = vectorizer.get_feature_names()\n",
    "graph_frequencies(titleMatrix, titleFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(file):\n",
    "    with open(file) as f:\n",
    "        labelsContent = f.readlines()\n",
    "    labels = [x.split(',')[2] for x in labelsContent]\n",
    "    return labels\n",
    "\n",
    "labels = get_labels('topics_popular.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a sparse matrix and populates the \"BODY\" and \"TITLE\" features according to the \"LEWISSPLIT\" training or test tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_files/body_train.csv') as f:\n",
    "    bodyTrainContent = f.readlines()\n",
    "bodyTrainData = [x.split(',')[2] for x in bodyTrainContent]\n",
    "bodyTrainMatrix = vectorizer.transform(bodyTrainData)\n",
    "bodyTrainFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(bodyTrainMatrix, bodyTrainFeatures)\n",
    "\n",
    "with open('testing_files/body_test.csv') as f:\n",
    "    bodyTestContent = f.readlines()\n",
    "bodyTestData = [x.split(',')[2] for x in bodyTestContent]\n",
    "bodyTestMatrix = vectorizer.transform(bodyTestData)\n",
    "bodyTestFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(bodyTestMatrix, bodyTestFeatures)\n",
    "\n",
    "with open('training_files/title_train.csv') as f:\n",
    "    titleTrainContent = f.readlines()\n",
    "titleTrainData = [x.split(',')[2] for x in titleTrainContent]\n",
    "titleTrainMatrix = vectorizer.transform(titleTrainData)\n",
    "titleTrainFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(titleTrainMatrix, titleTrainFeatures)\n",
    "\n",
    "with open('testing_files/title_test.csv') as f:\n",
    "    titleTestContent = f.readlines()\n",
    "titleTestData = [x.split(',')[2] for x in titleTestContent]\n",
    "titleTestMatrix = vectorizer.transform(titleTestData)\n",
    "titleTestFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(titleTestMatrix, titleTestFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "Since there are 135 potential \"TOPICS\", there are 135 clusters with the top word frequencies. The first 5 clusters are displayed below with each run producing a different subset of words for each cluster. This analysis is a useful sanity check to identify that words that are grouped together align with predetermined topics located in topics_popular.csv\n",
    "\n",
    "Modified from: https://github.disney.com/JORDC054/twitter-friend-clusters/blob/master/twitter%20techvive%202018.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_no_improvements'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-53fd5378c71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmbk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniBatchKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'k-means++'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m135\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_no_improvements\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbodyMatrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#titleMatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_no_improvements'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "mbk = MiniBatchKMeans(init='k-means++', n_clusters=135, batch_size=2500, n_init=10, max_no_improvements=10, verbose=0)\n",
    "\n",
    "mbk.fit(bodyMatrix) #titleMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mbk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d2738fbb871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'cluster'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mclusters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mbk' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "clusters = mbk.labels_.tolist()\n",
    "\n",
    "frame = pd.DataFrame({'cluster' : clusters}, index = [clusters], columns = ['cluster'])\n",
    "#frame['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words per cluster:\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mbk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bac1402c1738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sort cluster centroids by proximity to centroid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0morder_centroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mbk' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Top words per cluster:\")\n",
    "print()\n",
    "\n",
    "#sort cluster centroids by proximity to centroid\n",
    "order_centroids = mbk.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"Cluster %d had top words:\" % i, end= ' ')\n",
    "    for ind in order_centroids[i, :30]:\n",
    "        print(bodyFeaturs[ind], end = ', ') #change to titleFeatures to view \"TITLE\" top words\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "The following code splits the data into train and test sections with the features determine dby the sparse matrix and labels created above.\n",
    "\n",
    "Using SKlearn train_test_split: \"BODY\" produces an accuracy of about 86% and \"TITLE\" produces an ac"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
