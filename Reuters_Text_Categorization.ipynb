{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters-21578 Text Categorization\n",
    "The goal of this section is to implement a machine learning model that correctly classifies a series of documents in the Reuters-21578 corpus. Each document's \"BODY\" and \"TITLE\" is used to predict the overall category, or \"TOPIC\", of the document.\n",
    "\n",
    "First, the frequency of top words in each document's \"BODY\" and \"TITLE\" is calculated and used to create a sparse matrix of features. The most popular \"TOPIC\" for each document comprises the list of labels\n",
    "\n",
    "The K-Means Clustering adds more value to analyzing the top words and groups them into 135 clusters, reflecting the 135 potential \"TOPICS\".\n",
    "\n",
    "The Naive Bayes algorithm uses two approaches to classify: SkLearn randomized the test_train_split and \"LEWISSPLIT\" predetermined split, which was used in the TOIS located in the Resources directory.\n",
    "    - Using the SkLearn split, \"BODY\" accurately classfies \n",
    "    - Using the \"LEWISSPLIT\", \"BODY\" classifies about"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency of Top Words\n",
    "This section determines the frequencies of top words in the entire corpus. The words are taken from either the text \"BODY\" or \"TITLE\".\n",
    "\n",
    "Words that do not have an impact on the overall categorization of the article, or stopwords, such as \"and\" and \"the\" are removed from the list of words. A sparse matrix is created for the features and a separate list is created with a single topic for each document ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from yellowbrick.text.freqdist import FreqDistVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = frozenset({'reuter', 'said'})\n",
    "english_stopwords = stop_words.ENGLISH_STOP_WORDS\n",
    "stopwords = stopwords.union(english_stopwords)\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = stopwords)\n",
    "\n",
    "def graph_frequencies(matrix, features):\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "    visualizer = FreqDistVisualizer(features=features, ax=ax)\n",
    "    visualizer.fit(matrix)\n",
    "    visualizer.poof()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a sparse matrix and populates features for BODY and TITLE\n",
    "with open('body_no_null.csv') as f:\n",
    "    bodyContent = f.readlines()\n",
    "bodyData = [x.split(',')[2] for x in bodyContent]\n",
    "bodyMatrix = vectorizer.fit_transform(bodyData)\n",
    "bodyFeatures = vectorizer.get_feature_names()\n",
    "graph_frequencies(bodyMatrix, bodyFeatures)\n",
    "\n",
    "with open('title_no_null.csv') as f:\n",
    "    titleContent = f.readlines()\n",
    "titleData = [x.split(',')[2] for x in titleContent]\n",
    "titleMatrix = vectorizer.fit_transform(titleData)\n",
    "titleFeatures = vectorizer.get_feature_names()\n",
    "graph_frequencies(titleMatrix, titleFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(file):\n",
    "    with open(file) as f:\n",
    "        labelsContent = f.readlines()\n",
    "    labels = [x.split(',')[2] for x in labelsContent]\n",
    "    return labels\n",
    "\n",
    "labels = get_labels('topics_popular.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a sparse matrix and populates the \"BODY\" and \"TITLE\" features according to the \"LEWISSPLIT\" training or test tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training_files/body_train.csv') as f:\n",
    "    bodyTrainContent = f.readlines()\n",
    "bodyTrainData = [x.split(',')[2] for x in bodyTrainContent]\n",
    "bodyTrainMatrix = vectorizer.transform(bodyTrainData)\n",
    "bodyTrainFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(bodyTrainMatrix, bodyTrainFeatures)\n",
    "\n",
    "with open('testing_files/body_test.csv') as f:\n",
    "    bodyTestContent = f.readlines()\n",
    "bodyTestData = [x.split(',')[2] for x in bodyTestContent]\n",
    "bodyTestMatrix = vectorizer.transform(bodyTestData)\n",
    "bodyTestFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(bodyTestMatrix, bodyTestFeatures)\n",
    "\n",
    "with open('training_files/title_train.csv') as f:\n",
    "    titleTrainContent = f.readlines()\n",
    "titleTrainData = [x.split(',')[2] for x in titleTrainContent]\n",
    "titleTrainMatrix = vectorizer.transform(titleTrainData)\n",
    "titleTrainFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(titleTrainMatrix, titleTrainFeatures)\n",
    "\n",
    "with open('testing_files/title_test.csv') as f:\n",
    "    titleTestContent = f.readlines()\n",
    "titleTestData = [x.split(',')[2] for x in titleTestContent]\n",
    "titleTestMatrix = vectorizer.transform(titleTestData)\n",
    "titleTestFeatures = vectorizer.get_feature_names()\n",
    "#graph_frequencies(titleTestMatrix, titleTestFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
